# 各部门爬虫翻页机制分析

**更新日期**: 2025.10.29  
**版本**: v3.0.1

## 📋 概述

本项目实现了对三个政府部门的政策数据爬取，每个部门的翻页机制因网站结构不同而有显著差异。

## 🏛️ 1. 住房和城乡建设部 (NationalSpider)

### 🔧 翻页实现方式
- **API类型**: RESTful API + JSON响应
- **翻页参数**: `pageNo` (页码) + `pageSize` (页大小)
- **页大小**: 30条/页
- **请求方式**: GET方法
- **URL**: `https://www.mohurd.gov.cn/api-gateway/jpaas-publish-server/front/page/build/unit`

### 📊 翻页机制特点

#### 1. **参数结构**
```python
param_json = {
    "pageNo": page_no,        # 当前页码（从1开始）
    "pageSize": page_size,     # 每页30条
    "loadEnabled": True,
    "search": "{}"
}
```

#### 2. **翻页循环逻辑**
```python
while True:  # 无固定页数限制，根据内容自动停止
    # 发送API请求
    params['paramJson'] = json.dumps(param_json)
    
    # 解析HTML响应内容
    html_content = data.get('data', {}).get('html', '')
    
    # 检查是否无内容
    if not html_content:
        break  # 无HTML内容，停止翻页
    
    # 更新时间区间跟踪
    if 超出时间范围:
        consecutive_out_of_range += 1
        if consecutive_out_of_range >= 5:  # 连续5页超出范围，停止
            break
    
    page_no += 1
```

#### 3. **翻页停止条件**
- ✅ **自动停止**: 当返回的HTML内容为空时
- ✅ **时间范围停止**: 连续5页超出目标时间范围时
- ✅ **手动停止**: 用户点击停止按钮时
- ✅ **无限翻页**: 理论上可以无限翻页（无上限）

#### 4. **特点分析**
- **优点**: 
  - API响应快速
  - 数据格式稳定（返回HTML片段）
  - 支持时间范围自动过滤
  - 无需复杂会话管理
  
- **缺点**:
  - 返回HTML而非结构化JSON
  - 需要解析HTML提取数据
  - 响应内容不稳定，可能出现空HTML

---

## 🏛️ 2. 广东省人民政府 (GuangdongSpider)

### 🔧 翻页实现方式
- **API类型**: POST表单提交 + HTML响应
- **翻页参数**: `Pager.PageIndex` (页码) + `Pager.PageSize` (页大小)
- **页大小**: 20条/页
- **请求方式**: POST方法
- **URL**: `https://gd.pkulaw.com/china/search/RecordSearch`

### 📊 翻页机制特点

#### 1. **参数结构**
```python
search_params = {
    'Pager.PageIndex': str(page_index),     # 当前页码（从1开始）
    'Pager.PageSize': str(page_size),       # 每页20条
    'OldPageIndex': str(old_page_index),     # 上一页索引（翻页校验）
    # ... 其他搜索参数
}
```

#### 2. **两步翻页机制**
该部门采用**两步翻页校验机制**：

```python
def _request_page_with_check(self, page_index, search_params, old_page_index=None):
    """两步翻页机制"""
    
    # 步骤1: 翻页校验接口
    check_url = "https://gd.pkulaw.com/china/search/RecordSearchCheck"
    check_resp = self.session.post(check_url, data=check_params, ...)
    
    # 步骤2: 数据请求接口
    search_url = "https://gd.pkulaw.com/china/search/RecordSearch"
    search_resp = self.session.post(search_url, data=search_params, ...)
    
    return search_resp
```

#### 3. **翻页循环逻辑**
```python
page_index = 1
max_pages = 999999  # 无上限
empty_page_count = 0
max_empty_pages = 10  # 连续空页限制

while page_index <= max_pages and empty_page_count < max_empty_pages:
    # 构建搜索参数
    post_data = self._get_search_parameters(
        keywords=keywords,
        category_code=category_code,
        page_index=page_index,
        page_size=20
    )
    
    # 两步翻页请求
    resp = self._request_page_with_check(page_index, post_data)
    
    if len(page_policies) == 0:
        empty_page_count += 1
        if empty_page_count >= max_empty_pages:
            break
    else:
        empty_page_count = 0  # 重置空页计数
    
    page_index += 1
```

#### 4. **多种翻页策略**
广东省爬虫实现了**4种不同的翻页策略**：

##### 策略1: 分类遍历（传统方式）
- 遍历所有分类（7个主要分类）
- 每个分类分别翻页
- 页大小: 20条/页
- 最大连续空页: 10页

##### 策略2: 快速搜索（新增）
- 跳过分类遍历
- 直接使用高级搜索
- 页大小: 50条/页（更大）
- 翻页速度更快

##### 策略3: 重复翻页校验
- 使用`OldPageIndex`参数
- 确保翻页有效
- 防止重复请求

##### 策略4: 优化翻页（备用）
- 更大的页大小（100条/页）
- 限制总页数（500页）
- 适用于大量数据检索

#### 5. **翻页停止条件**
- ✅ **连续空页停止**: 连续10页无数据时停止
- ✅ **手动停止**: 用户点击停止按钮时
- ✅ **访问限制停止**: 检测到访问限制时停止
- ✅ **会话失败停止**: 会话轮换失败时停止

#### 6. **特点分析**
- **优点**: 
  - 支持多种翻页策略
  - 两步校验机制提高成功率
  - 支持分类遍历和快速搜索
  - 自动处理访问限制
  
- **缺点**:
  - 翻页机制复杂
  - 需要维护会话状态
  - 需要处理OldPageIndex参数
  - 响应时间较长

---

## 🏛️ 3. 自然资源部 (MNRSpider)

### 🔧 翻页实现方式
- **API类型**: GET参数 + 搜索结果页面
- **翻页参数**: `page` (页码) + `perpage` (每页条数)
- **页大小**: 20条/页
- **请求方式**: GET方法
- **URL**: `https://search.mnr.gov.cn/was5/web/search`

### 📊 翻页机制特点

#### 1. **参数结构**
```python
params = {
    'channelid': '216640',           # 固定频道ID
    'searchword': search_query,      # 搜索关键词
    'page': page,                    # 当前页码
    'perpage': 20,                   # 每页20条
    'searchtype': 'title',           # 搜索标题
    'orderby': 'RELEVANCE'          # 按相关性排序
}

# 时间过滤（可选）
if start_date:
    params['starttime'] = start_date
if end_date:
    params['endtime'] = end_date
```

#### 2. **翻页循环逻辑**
```python
page = 1
max_pages = 999999  # 无上限
consecutive_empty_pages = 0
max_consecutive_empty = 3  # 连续空页限制（仅3页）

while page <= self.max_pages:
    # 发送搜索请求
    resp = requests.get(self.search_api, params=params)
    
    # 解析HTML响应
    soup = BeautifulSoup(resp.text, 'html.parser')
    policies = self._parse_search_results(soup)
    
    if len(policies) == 0:
        consecutive_empty_pages += 1
        if consecutive_empty_pages >= 3:
            break  # 连续3页无数据，停止翻页
    else:
        consecutive_empty_pages = 0
    
    page += 1
```

#### 3. **翻页停止条件**
- ✅ **连续空页停止**: 连续3页无数据时停止
- ✅ **手动停止**: 用户点击停止按钮时
- ✅ **分类完成**: 当前分类所有页面爬取完毕

#### 4. **分类遍历机制**
```python
# 自然资源部支持按分类爬取
for category_name in categories_to_search:
    category_config = self.categories[category_name]
    
    # 为每个分类构建搜索参数
    if category_name in self.categories:
        category_code = self.categories[category_name]['code']
        search_query = f"themecat=({category_code})"
    
    # 对该分类进行翻页
    page = 1
    while page <= max_pages:
        # ... 翻页逻辑
        page += 1
```

#### 5. **特点分析**
- **优点**: 
  - 翻页机制简单直观
  - 支持分类遍历
  - 支持时间范围过滤
  - URL参数清晰
  - 响应速度快
  
- **缺点**:
  - 需解析HTML搜索结果
  - 空页检测不够敏感（仅3页）
  - 分页参数较多
  - 无高级搜索API

---

## 📊 翻页机制对比分析

| 特征 | 住建部 | 广东省 | 自然资源部 |
|------|--------|--------|------------|
| **API类型** | RESTful JSON | POST表单 | GET参数 |
| **页大小** | 30条/页 | 20条/页 | 20条/页 |
| **翻页参数** | pageNo | PageIndex | page |
| **请求方式** | GET | POST | GET |
| **翻页校验** | ❌ 无需校验 | ✅ 两步校验 | ❌ 无需校验 |
| **最大连续空页** | 5页 | 10页 | 3页 |
| **会话管理** | 简单 | 复杂（需要会话轮换） | 简单 |
| **分类遍历** | ❌ 不支持 | ✅ 支持（7个分类） | ✅ 支持（23个分类） |
| **时间过滤** | ✅ 支持 | ✅ 支持 | ✅ 支持 |
| **翻页策略** | 单一 | 4种策略 | 单一 |

---

## 🔍 关键代码位置

### 住建部 (NationalSpider)
- **文件**: `src/space_planning/spider/national.py`
- **翻页函数**: `crawl_policies()` (第61-387行)
- **关键逻辑**: 第106-277行

### 广东省 (GuangdongSpider)
- **文件**: `src/space_planning/spider/guangdong.py`
- **翻页函数**: `crawl_policies()` (第692-959行)
- **两步校验**: `_request_page_with_check()` (第180-273行)
- **关键逻辑**: 第762-859行（分类遍历翻页）

### 自然资源部 (MNRSpider)
- **文件**: `src/space_planning/spider/mnr.py`
- **翻页函数**: `crawl_policies()` (第72-378行)
- **关键逻辑**: 第134-200行（分类翻页）

---

## 💡 优化建议

### 1. 住建部
- ✅ **已完成**: 时间区间智能停止
- 💡 **建议**: 增加返回数据验证，确保HTML有效

### 2. 广东省
- ✅ **已完成**: 多种翻页策略、会话轮换
- 💡 **建议**: 
  - 优化两步校验机制，减少请求次数
  - 增加翻页失败重试机制
  - 添加翻页进度持久化

### 3. 自然资源部
- ✅ **已完成**: 分类遍历、时间过滤
- 💡 **建议**: 
  - 增加连续空页检测敏感度（由3页提升到5页）
  - 优化HTML解析逻辑
  - 添加搜索词高亮处理

---

## 🔧 技术细节

### 广东省两步翻页校验机制详解

```python
def _request_page_with_check(self, page_index, search_params, old_page_index=None):
    """
    广东省独特的翻页机制：
    
    1. 先请求校验接口，确保翻页有效
    2. 再请求数据接口，获取实际数据
    
    这种机制可以：
    - 防止恶意爬虫
    - 确保翻页顺序正确
    - 提高数据获取成功率
    """
    
    # 第1步：翻页校验
    check_params = {
        'PageIndex': page_index,
        'OldPageIndex': old_page_index or '',
        'SessionId': self.session.cookies.get('JSESSIONID', ''),
        # ...
    }
    check_resp = self.session.post(check_url, data=check_params)
    
    # 第2步：数据请求
    search_params['OldPageIndex'] = old_page_index or ''
    search_resp = self.session.post(search_url, data=search_params)
    
    return search_resp
```

### 三部门翻页参数对比

```python
# 住建部
param_json = {"pageNo": 1, "pageSize": 30}

# 广东省
search_params = {
    'Pager.PageIndex': '1',
    'Pager.PageSize': '20',
    'OldPageIndex': ''  # 翻页校验用
}

# 自然资源部
params = {
    'page': 1,
    'perpage': 20,
    'channelid': '216640'
}
```

---

## 📝 总结

三个部门的翻页机制各有特色：

1. **住建部**: 最简单，API清晰，响应快速
2. **广东省**: 最复杂，需要两步校验，但支持多种策略
3. **自然资源部**: 中等复杂度，支持分类遍历

所有爬虫都实现了：
- ✅ 智能停止机制（连续空页检测）
- ✅ 时间范围过滤
- ✅ 手动停止支持
- ✅ 错误处理和重试机制

---

**文档版本**: 1.0  
**最后更新**: 2025.10.29  
**维护者**: ViVi141

