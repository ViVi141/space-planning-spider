import sqlite3
import os
import sys
import shutil
from datetime import datetime, timedelta
import json
import logging

# å¯¼å…¥é…ç½®æ¨¡å—
from . import config
from .exceptions import (
    DatabaseConnectionError,
    DatabaseQueryError,
    DatabaseIntegrityError,
    DatabaseError
)
from .db_connection import get_db_connection

logger = logging.getLogger(__name__)

def get_database_path():
    """è·å–æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨æ–°çš„é…ç½®ç³»ç»Ÿ"""
    return config.app_config.get_database_path()

def get_backup_dir():
    """è·å–å¤‡ä»½ç›®å½•"""
    return config.app_config.get_backup_dir()

def get_conn():
    """
    è·å–æ•°æ®åº“è¿æ¥ï¼ˆå‘åå…¼å®¹å‡½æ•°ï¼‰
    
    æ³¨æ„ï¼šæ¨èä½¿ç”¨ get_db_connection() ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    è¿™æ ·å¯ä»¥ç¡®ä¿è¿æ¥æ­£ç¡®å…³é—­
    """
    db_path = get_database_path()
    # ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
    try:
        os.makedirs(os.path.dirname(db_path), exist_ok=True)
        return sqlite3.connect(db_path)
    except sqlite3.Error as e:
        raise DatabaseConnectionError(f"æ— æ³•è¿æ¥æ•°æ®åº“ {db_path}: {e}") from e
    except OSError as e:
        raise DatabaseConnectionError(f"æ— æ³•åˆ›å»ºæ•°æ®åº“ç›®å½•: {e}") from e

def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    conn = get_conn()
    c = conn.cursor()
    
    # åˆ›å»ºä¸»è¡¨
    c.execute('''
        CREATE TABLE IF NOT EXISTS policy (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            level TEXT,
            title TEXT,
            pub_date TEXT,
            source TEXT,
            content TEXT,
            category TEXT,
            crawl_time TEXT
        )
    ''')
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ categoryå­—æ®µï¼ˆæ•°æ®åº“è¿ç§»ï¼‰
    try:
        c.execute('SELECT category FROM policy LIMIT 1')
    except sqlite3.OperationalError:
        # categoryå­—æ®µä¸å­˜åœ¨ï¼Œéœ€è¦æ·»åŠ 
        logger.info("æ­£åœ¨æ·»åŠ categoryå­—æ®µåˆ°ç°æœ‰æ•°æ®åº“...")
        c.execute('ALTER TABLE policy ADD COLUMN category TEXT')
        logger.info("categoryå­—æ®µæ·»åŠ å®Œæˆ")
    
    # åˆ›å»ºå…¨æ–‡æ£€ç´¢è¡¨
    c.execute('''
        CREATE VIRTUAL TABLE IF NOT EXISTS policy_fts USING fts5(
            title, content, level, content='policy', content_rowid='id'
        )
    ''')
    
    # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
    # 1. levelå­—æ®µç´¢å¼•ï¼ˆç”¨äºæŒ‰æœºæ„ç­›é€‰ï¼‰
    c.execute('''
        CREATE INDEX IF NOT EXISTS idx_policy_level ON policy(level)
    ''')
    
    # 2. pub_dateå­—æ®µç´¢å¼•ï¼ˆç”¨äºæ—¶é—´èŒƒå›´æŸ¥è¯¢å’Œæ’åºï¼‰
    c.execute('''
        CREATE INDEX IF NOT EXISTS idx_policy_pub_date ON policy(pub_date)
    ''')
    
    # 3. ç»„åˆç´¢å¼•ï¼ˆlevel + pub_dateï¼Œç”¨äºå¸¸è§æŸ¥è¯¢æ¨¡å¼ï¼‰
    c.execute('''
        CREATE INDEX IF NOT EXISTS idx_policy_level_date ON policy(level, pub_date DESC)
    ''')
    
    # 4. titleç´¢å¼•ï¼ˆç”¨äºæ ‡é¢˜æœç´¢ï¼‰
    c.execute('''
        CREATE INDEX IF NOT EXISTS idx_policy_title ON policy(title)
    ''')
    
    # 5. sourceç´¢å¼•ï¼ˆç”¨äºæ¥æºç­›é€‰ï¼‰
    c.execute('''
        CREATE INDEX IF NOT EXISTS idx_policy_source ON policy(source)
    ''')
    
    # 6. categoryç´¢å¼•ï¼ˆç”¨äºåˆ†ç±»ç­›é€‰ï¼‰
    c.execute('''
        CREATE INDEX IF NOT EXISTS idx_policy_category ON policy(category)
    ''')
    
    # 7. crawl_timeç´¢å¼•ï¼ˆç”¨äºæŒ‰çˆ¬å–æ—¶é—´æŸ¥è¯¢ï¼‰
    c.execute('''
        CREATE INDEX IF NOT EXISTS idx_policy_crawl_time ON policy(crawl_time)
    ''')
    
    # åˆ›å»ºç³»ç»Ÿä¿¡æ¯è¡¨
    c.execute('''
        CREATE TABLE IF NOT EXISTS system_info (
            key TEXT PRIMARY KEY,
            value TEXT,
            update_time TEXT
        )
    ''')
    
    # åˆå§‹åŒ–ç³»ç»Ÿä¿¡æ¯
    c.execute('''
        INSERT OR IGNORE INTO system_info (key, value, update_time) 
        VALUES (?, ?, ?)
    ''', ('db_version', '2.0', datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
    
    conn.commit()
    conn.close()
    
    logger.info(f"æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {get_database_path()}")

def backup_database():
    """å¤‡ä»½æ•°æ®åº“"""
    try:
        db_path = get_database_path()
        if not os.path.exists(db_path):
            logger.warning("æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— éœ€å¤‡ä»½")
            return False
        
        backup_dir = get_backup_dir()
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_filename = f"policy_backup_{timestamp}.db"
        backup_path = os.path.join(backup_dir, backup_filename)
        
        # å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
        shutil.copy2(db_path, backup_path)
        
        # æ›´æ–°æœ€åå¤‡ä»½æ—¶é—´
        config.app_config.update_config('last_backup_time', datetime.now().isoformat())
        
        logger.info(f"æ•°æ®åº“å¤‡ä»½å®Œæˆ: {backup_path}")
        
        # æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶
        cleanup_old_backups()
        
        return True
    except OSError as e:
        logger.error(f"æ•°æ®åº“å¤‡ä»½å¤±è´¥ï¼ˆæ–‡ä»¶æ“ä½œé”™è¯¯ï¼‰: {e}", exc_info=True)
        return False
    except Exception as e:
        logger.error(f"æ•°æ®åº“å¤‡ä»½å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}", exc_info=True)
        return False

def cleanup_old_backups():
    """æ¸…ç†æ—§çš„å¤‡ä»½æ–‡ä»¶"""
    try:
        backup_dir = get_backup_dir()
        max_backup_count = config.app_config.get_database_config().get('max_backup_count', 10)
        
        # è·å–æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
        backup_files = []
        for filename in os.listdir(backup_dir):
            if filename.startswith('policy_backup_') and filename.endswith('.db'):
                file_path = os.path.join(backup_dir, filename)
                backup_files.append((file_path, os.path.getmtime(file_path)))
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        backup_files.sort(key=lambda x: x[1], reverse=True)
        
        # åˆ é™¤å¤šä½™çš„å¤‡ä»½æ–‡ä»¶
        if len(backup_files) > max_backup_count:
            for file_path, _ in backup_files[max_backup_count:]:
                os.remove(file_path)
                logger.debug(f"åˆ é™¤æ—§å¤‡ä»½æ–‡ä»¶: {file_path}")
    except OSError as e:
        logger.error(f"æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶å¤±è´¥ï¼ˆæ–‡ä»¶æ“ä½œé”™è¯¯ï¼‰: {e}", exc_info=True)
    except Exception as e:
        logger.error(f"æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}", exc_info=True)

def clear_database():
    """æ¸…ç†æ•°æ®åº“ - åˆ é™¤æ‰€æœ‰æ”¿ç­–æ•°æ®ï¼ˆä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # è·å–æ¸…ç†å‰çš„æ•°æ®ç»Ÿè®¡
            c.execute('SELECT COUNT(*) FROM policy')
            policy_count = c.fetchone()[0]
            
            # åˆ é™¤æ‰€æœ‰æ”¿ç­–æ•°æ®
            c.execute('DELETE FROM policy')
            
            # æ¸…ç†FTSè¡¨
            c.execute('DELETE FROM policy_fts')
            
            # é‡ç½®è‡ªå¢ID
            c.execute('DELETE FROM sqlite_sequence WHERE name="policy"')
            
            # ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¼šè‡ªåŠ¨commit
        
        # åœ¨è¿æ¥å…³é—­åæ‰§è¡Œå¤‡ä»½ï¼ˆé¿å…æ­»é”ï¼‰
        if policy_count > 0:
            backup_database()
        
        logger.info(f"æ•°æ®åº“æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {policy_count} æ¡æ”¿ç­–æ•°æ®")
        return True, policy_count
    except DatabaseError as e:
        logger.error(f"æ•°æ®åº“æ¸…ç†å¤±è´¥ï¼ˆæ•°æ®åº“é”™è¯¯ï¼‰: {e}", exc_info=True)
        return False, 0
    except Exception as e:
        logger.error(f"æ•°æ®åº“æ¸…ç†å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}", exc_info=True)
        return False, 0

def should_backup_database():
    """æ£€æŸ¥æ˜¯å¦éœ€è¦å¤‡ä»½æ•°æ®åº“"""
    try:
        backup_enabled = config.app_config.get_database_config().get('backup_enabled', True)
        if not backup_enabled:
            return False
        
        last_backup_time = config.app_config.get_config('last_backup_time')
        if not last_backup_time:
            return True
        
        backup_interval = config.app_config.get_database_config().get('backup_interval', 7)
        last_backup = datetime.fromisoformat(last_backup_time)
        days_since_backup = (datetime.now() - last_backup).days
        
        return days_since_backup >= backup_interval
    except Exception as e:
        logger.error(f"æ£€æŸ¥å¤‡ä»½çŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        return False

def insert_policy(level, title, pub_date, source, content, crawl_time, category=None):
    """æ’å…¥æ”¿ç­–æ•°æ® - å¢å¼ºå»é‡é€»è¾‘ï¼ˆä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰"""
    from .db_connection import get_db_connection
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # å¢å¼ºå»é‡é€»è¾‘ï¼šæ£€æŸ¥å¤šç§ç»„åˆ
            # 1. æ ‡é¢˜+æ—¥æœŸç»„åˆ
            c.execute('SELECT id FROM policy WHERE title=? AND pub_date=?', (title, pub_date))
            if c.fetchone():
                logger.debug(f"è·³è¿‡é‡å¤æ”¿ç­–: {title} ({pub_date})")
                return None
            
            # 2. æ ‡é¢˜+æ¥æºç»„åˆï¼ˆå¦‚æœæ¥æºç›¸åŒï¼‰
            if source:
                c.execute('SELECT id FROM policy WHERE title=? AND source=?', (title, source))
                if c.fetchone():
                    logger.debug(f"è·³è¿‡é‡å¤æ”¿ç­–: {title} (æ¥æº: {source})")
                    return None
            
            # 3. å†…å®¹ç›¸ä¼¼åº¦æ£€æŸ¥ï¼ˆå¦‚æœå†…å®¹å®Œå…¨ç›¸åŒï¼‰
            c.execute('SELECT id FROM policy WHERE content=?', (content,))
            if c.fetchone():
                logger.debug(f"è·³è¿‡é‡å¤å†…å®¹æ”¿ç­–: {title}")
                return None
            
            c.execute('''INSERT INTO policy (level, title, pub_date, source, content, category, crawl_time)
                         VALUES (?, ?, ?, ?, ?, ?, ?)''',
                      (level, title, pub_date, source, content, category, crawl_time))
            rowid = c.lastrowid
            
            # åŒæ­¥åˆ°FTSè¡¨
            c.execute('INSERT INTO policy_fts(rowid, title, content, level) VALUES (?, ?, ?, ?)',
                      (rowid, title, content, level))
            
            # ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¼šè‡ªåŠ¨commit
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤‡ä»½ï¼ˆåœ¨è¿æ¥å…³é—­åï¼‰
        if should_backup_database():
            backup_database()
        
        return rowid
    except DatabaseIntegrityError as e:
        logger.warning(f"æ’å…¥æ”¿ç­–å¤±è´¥ï¼ˆæ•°æ®å®Œæ•´æ€§çº¦æŸï¼‰: {e}")
        return None
    except DatabaseQueryError as e:
        logger.error(f"æ’å…¥æ”¿ç­–å¤±è´¥ï¼ˆæ•°æ®åº“æ“ä½œé”™è¯¯ï¼‰: {e}", exc_info=True)
        raise
    except DatabaseError as e:
        logger.error(f"æ’å…¥æ”¿ç­–å¤±è´¥ï¼ˆæ•°æ®åº“é”™è¯¯ï¼‰: {e}", exc_info=True)
        raise
    except Exception as e:
        logger.error(f"æ’å…¥æ”¿ç­–å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}", exc_info=True)
        return None

def deduplicate_database():
    """æ¸…ç†æ•°æ®åº“ä¸­çš„é‡å¤è®°å½•ï¼ˆä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰"""
    from .db_connection import get_db_connection
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            logger.info("ğŸ” å¼€å§‹æ¸…ç†æ•°æ®åº“é‡å¤è®°å½•...")
            
            # è·å–æ‰€æœ‰æ”¿ç­–
            c.execute('SELECT id, title, pub_date, source, content FROM policy ORDER BY id')
            all_policies = c.fetchall()
            
            if not all_policies:
                logger.info("æ•°æ®åº“ä¸­æ²¡æœ‰æ”¿ç­–æ•°æ®")
                return {'success': True, 'removed': 0, 'total': 0}
            
            logger.info(f"æ€»æ”¿ç­–æ•°é‡: {len(all_policies)}")
            
            # æŒ‰æ ‡é¢˜+æ—¥æœŸåˆ†ç»„ï¼Œä¿ç•™æœ€æ–°çš„è®°å½•
            policy_groups = {}
            for policy in all_policies:
                policy_id, title, pub_date, source, content = policy
                key = (title, pub_date)
                if key not in policy_groups:
                    policy_groups[key] = []
                policy_groups[key].append(policy)
            
            # æ‰¾å‡ºé‡å¤çš„è®°å½•
            duplicates_to_remove = []
            for key, policies in policy_groups.items():
                if len(policies) > 1:
                    # ä¿ç•™IDæœ€å¤§çš„è®°å½•ï¼ˆæœ€æ–°çš„ï¼‰ï¼Œåˆ é™¤å…¶ä»–çš„
                    policies.sort(key=lambda x: x[0])  # æŒ‰IDæ’åº
                    duplicates_to_remove.extend(policies[:-1])  # é™¤äº†æœ€åä¸€ä¸ªéƒ½åˆ é™¤
            
            if not duplicates_to_remove:
                logger.info("âœ… æ²¡æœ‰å‘ç°é‡å¤è®°å½•")
                return {'success': True, 'removed': 0, 'total': len(all_policies)}
            
            logger.info(f"å‘ç° {len(duplicates_to_remove)} æ¡é‡å¤è®°å½•éœ€è¦åˆ é™¤")
            
            # åˆ é™¤é‡å¤è®°å½•
            removed_count = 0
            for policy in duplicates_to_remove:
                policy_id, title, pub_date, source, content = policy
                try:
                    # åˆ é™¤ä¸»è¡¨è®°å½•
                    c.execute('DELETE FROM policy WHERE id = ?', (policy_id,))
                    # åˆ é™¤FTSè¡¨è®°å½•
                    c.execute('DELETE FROM policy_fts WHERE rowid = ?', (policy_id,))
                    removed_count += 1
                    logger.debug(f"åˆ é™¤é‡å¤è®°å½•: {title} ({pub_date})")
                except sqlite3.Error as e:
                    logger.error(f"åˆ é™¤è®°å½•å¤±è´¥ ID {policy_id}ï¼ˆæ•°æ®åº“é”™è¯¯ï¼‰: {e}", exc_info=True)
                except Exception as e:
                    logger.error(f"åˆ é™¤è®°å½•å¤±è´¥ ID {policy_id}ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}", exc_info=True)
            
            # ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¼šè‡ªåŠ¨commit
            
            # é‡æ–°ç»Ÿè®¡
            c.execute('SELECT COUNT(*) FROM policy')
            new_count = c.fetchone()[0]
            
            logger.info(f"âœ… æ¸…ç†å®Œæˆï¼åˆ é™¤äº† {removed_count} æ¡é‡å¤è®°å½•ï¼Œå‰©ä½™ {new_count} æ¡è®°å½•")
            
            return {
                'success': True,
                'removed': removed_count,
                'total': new_count,
                'original': len(all_policies)
            }
        
    except DatabaseError as e:
        logger.error(f"æ¸…ç†æ•°æ®åº“å¤±è´¥ï¼ˆæ•°æ®åº“é”™è¯¯ï¼‰: {e}", exc_info=True)
        return {'success': False, 'error': f'æ•°æ®åº“é”™è¯¯: {str(e)}'}
    except Exception as e:
        logger.error(f"æ¸…ç†æ•°æ®åº“å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}", exc_info=True)
        return {'success': False, 'error': str(e)}

def search_policies(level=None, keywords=None, start_date=None, end_date=None, limit=None, offset=0):
    """
    æœç´¢æ”¿ç­–ï¼Œæ”¯æŒæ—¶é—´åŒºé—´ï¼ˆæ”¹è¿›ï¼šæ·»åŠ è¾“å…¥éªŒè¯å’Œåˆ†é¡µï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰
    
    Args:
        level: æœºæ„çº§åˆ«
        keywords: å…³é”®è¯åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶ï¼ˆç”¨äºåˆ†é¡µï¼‰
        offset: ç»“æœåç§»é‡ï¼ˆç”¨äºåˆ†é¡µï¼‰
    
    Returns:
        æ”¿ç­–æ•°æ®åˆ—è¡¨
    """
    # å¯¼å…¥éªŒè¯å™¨å’Œè¿æ¥ç®¡ç†å™¨
    from ..utils.validator import InputValidator
    from .db_connection import get_db_connection
    
    try:
        # éªŒè¯limitå’Œoffsetå‚æ•°ï¼ˆé˜²æ­¢æ³¨å…¥å’ŒDoSæ”»å‡»ï¼‰
        validated_limit = InputValidator.validate_integer(limit, min_val=1, max_val=10000, default=None)
        validated_offset = InputValidator.validate_integer(offset, min_val=0, max_val=1000000, default=0)
        
        # éªŒè¯levelå‚æ•°ï¼ˆç™½åå•æœºåˆ¶ï¼‰
        validated_level = None
        if level:
            validated_level = InputValidator.sanitize_level(level)
            if not validated_level:
                logger.warning(f"æ— æ•ˆçš„æœºæ„çº§åˆ«å‚æ•°ï¼Œå·²å¿½ç•¥: {level}")
        
        with get_db_connection() as conn:
            c = conn.cursor()
            params = []
            # ä½¿ç”¨åˆ—è¡¨æ„å»ºSQLç‰‡æ®µï¼Œé¿å…å­—ç¬¦ä¸²æ‹¼æ¥
            where_conditions = []
            
            # éªŒè¯å’Œæ·»åŠ æ—¥æœŸæ¡ä»¶
            if start_date and end_date:
                validated_start = InputValidator.validate_date(start_date)
                validated_end = InputValidator.validate_date(end_date)
                if validated_start and validated_end:
                    where_conditions.append('p.pub_date BETWEEN ? AND ?')
                    params.extend([validated_start, validated_end])
                else:
                    logger.warning(f"æ— æ•ˆçš„æ—¥æœŸå‚æ•°: {start_date} - {end_date}")
            
            # æ„å»ºWHEREå­å¥ï¼ˆå®‰å…¨çš„æ–¹å¼ï¼‰
            where_clause = ''
            if where_conditions:
                where_clause = ' AND ' + ' AND '.join(where_conditions)
            
            # éªŒè¯å’Œæ¸…ç†å…³é”®è¯
            if keywords:
                # æ¸…ç†å…³é”®è¯ï¼ˆé˜²æ­¢æ³¨å…¥æ”»å‡»ï¼‰
                sanitized_keywords = []
                for kw in keywords:
                    if isinstance(kw, str):
                        sanitized = InputValidator.sanitize_fts_query(kw)
                        if sanitized:
                            sanitized_keywords.append(sanitized)
                
                if sanitized_keywords:
                    # æ„å»ºFTSæŸ¥è¯¢ï¼ˆä½¿ç”¨å‚æ•°åŒ–æ–¹å¼ï¼‰
                    if validated_level:
                        # ä½¿ç”¨å‚æ•°åŒ–æ–¹å¼æ„å»ºFTSæŸ¥è¯¢
                        fts_query_parts = [f"level:{validated_level}"]
                        fts_query_parts.append(f"({' OR '.join(sanitized_keywords)})")
                        fts_query = ' AND '.join(fts_query_parts)
                    else:
                        fts_query = ' OR '.join(sanitized_keywords)
                    
                    # å†æ¬¡æ¸…ç†å®Œæ•´æŸ¥è¯¢ï¼ˆåŒé‡ä¿æŠ¤ï¼‰
                    fts_query = InputValidator.sanitize_fts_query(fts_query, max_length=500)
                    
                    if fts_query:
                        # ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢ï¼ˆé¿å…SQLæ³¨å…¥ï¼‰
                        sql = '''SELECT p.id, p.level, p.title, p.pub_date, p.source, p.content, p.category 
                                 FROM policy p JOIN policy_fts fts ON p.id = fts.rowid 
                                 WHERE policy_fts MATCH ?'''
                        sql += where_clause
                        sql += ' ORDER BY p.pub_date DESC'
                        
                        query_params = [fts_query] + params
                        
                        if validated_limit:
                            sql += ' LIMIT ? OFFSET ?'
                            query_params.extend([validated_limit, validated_offset])
                        
                        c.execute(sql, query_params)
                    else:
                        # æŸ¥è¯¢è¢«è¿‡æ»¤ï¼Œè¿”å›ç©ºç»“æœï¼ˆä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢ï¼‰
                        sql = '''SELECT id, level, title, pub_date, source, content, category 
                                 FROM policy p WHERE 1=0'''
                        sql += where_clause
                        c.execute(sql, params)
                else:
                    # æ‰€æœ‰å…³é”®è¯éƒ½è¢«è¿‡æ»¤ï¼Œä½¿ç”¨æ™®é€šæŸ¥è¯¢
                    keywords = None
            
            if not keywords:
                # æ™®é€šæŸ¥è¯¢ï¼ˆä¸ä½¿ç”¨FTSï¼‰
                sql = '''SELECT id, level, title, pub_date, source, content, category 
                         FROM policy p'''
                
                if validated_level:
                    sql += ' WHERE level = ?'
                    sql += where_clause
                    params = [validated_level] + params
                elif where_clause:
                    sql += ' WHERE 1=1' + where_clause
                
                sql += ' ORDER BY pub_date DESC'
                
                if validated_limit:
                    sql += ' LIMIT ? OFFSET ?'
                    params.extend([validated_limit, validated_offset])
                
                c.execute(sql, params)
            
            results = c.fetchall()
            return results
    except Exception as e:
        logger.error(f"æœç´¢æ”¿ç­–å¤±è´¥: {e}", exc_info=True)
        return []

def get_policy_by_id(policy_id):
    """
    æ ¹æ®IDè·å–æ”¿ç­–è¯¦æƒ…ï¼ˆæ”¹è¿›ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰
    
    Args:
        policy_id: æ”¿ç­–ID
    
    Returns:
        æ”¿ç­–æ•°æ®å…ƒç»„æˆ–None
    """
    from .db_connection import get_db_connection
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute('SELECT * FROM policy WHERE id = ?', (policy_id,))
            result = c.fetchone()
            return result
    except Exception as e:
        logger.error(f"è·å–æ”¿ç­–è¯¦æƒ…å¤±è´¥ ID {policy_id}: {e}", exc_info=True)
        return None

def get_database_info():
    """è·å–æ•°æ®åº“ä¿¡æ¯ï¼ˆæ”¹è¿›ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰"""
    from .db_connection import get_db_connection
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # è·å–æ”¿ç­–æ•°é‡
            c.execute('SELECT COUNT(*) FROM policy')
            policy_count = c.fetchone()[0]
            
            # è·å–æœ€æ–°æ”¿ç­–æ—¶é—´
            c.execute('SELECT MAX(pub_date) FROM policy')
            latest_date = c.fetchone()[0]
            
            # è·å–æ•°æ®åº“æ–‡ä»¶å¤§å°
            db_path = get_database_path()
            try:
                if os.path.exists(db_path):
                    stat_info = os.stat(db_path)
                    file_size = stat_info.st_size
                else:
                    file_size = 0
            except (OSError, OverflowError):
                file_size = 0
            
            # è·å–æœ€åå¤‡ä»½æ—¶é—´
            last_backup_time = config.app_config.get_config('last_backup_time')
            
            return {
                'policy_count': policy_count,
                'latest_date': latest_date,
                'file_size': file_size,
                'file_size_mb': round(float(file_size) / (1024 * 1024), 2),
                'last_backup_time': last_backup_time,
                'database_path': db_path,
                'backup_dir': get_backup_dir()
            }
    except sqlite3.Error as e:
        logger.error(f"è·å–æ•°æ®åº“ä¿¡æ¯å¤±è´¥ï¼ˆæ•°æ®åº“é”™è¯¯ï¼‰: {e}", exc_info=True)
        return {}
    except Exception as e:
        logger.error(f"è·å–æ•°æ®åº“ä¿¡æ¯å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}", exc_info=True)
        return {}

def restore_database(backup_file):
    """ä»å¤‡ä»½æ–‡ä»¶æ¢å¤æ•°æ®åº“"""
    try:
        db_path = get_database_path()
        backup_path = os.path.join(get_backup_dir(), backup_file)
        
        if not os.path.exists(backup_path):
            logger.warning(f"å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_path}")
            return False
        
        # å¤‡ä»½å½“å‰æ•°æ®åº“
        if os.path.exists(db_path):
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            current_backup = os.path.join(get_backup_dir(), f"before_restore_{timestamp}.db")
            shutil.copy2(db_path, current_backup)
            logger.info(f"å½“å‰æ•°æ®åº“å·²å¤‡ä»½åˆ°: {current_backup}")
        
        # æ¢å¤æ•°æ®åº“
        shutil.copy2(backup_path, db_path)
        logger.info(f"æ•°æ®åº“æ¢å¤å®Œæˆ: {backup_path}")
        return True
    except (OSError, IOError) as e:
        logger.error(f"æ•°æ®åº“æ¢å¤å¤±è´¥ï¼ˆæ–‡ä»¶æ“ä½œé”™è¯¯ï¼‰: {e}", exc_info=True)
        return False
    except Exception as e:
        logger.error(f"æ•°æ®åº“æ¢å¤å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}", exc_info=True)
        return False

def get_backup_files():
    """è·å–æ‰€æœ‰å¤‡ä»½æ–‡ä»¶"""
    try:
        backup_dir = get_backup_dir()
        backup_files = []
        
        for filename in os.listdir(backup_dir):
            if filename.startswith('policy_backup_') and filename.endswith('.db'):
                file_path = os.path.join(backup_dir, filename)
                try:
                    # ä½¿ç”¨os.staté¿å…å¤§æ–‡ä»¶å¤§å°æº¢å‡º
                    stat_info = os.stat(file_path)
                    file_size = stat_info.st_size
                    file_time = datetime.fromtimestamp(stat_info.st_mtime)
                    
                    # å®‰å…¨è®¡ç®—æ–‡ä»¶å¤§å°MBï¼Œé¿å…æº¢å‡º
                    file_size_mb = round(float(file_size) / (1024 * 1024), 2)
                    
                    backup_files.append({
                        'filename': filename,
                        'file_path': file_path,
                        'file_size': file_size,
                        'file_size_mb': file_size_mb,
                        'file_time': file_time.strftime('%Y-%m-%d %H:%M:%S')
                    })
                except (OSError, OverflowError) as e:
                    logger.warning(f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
                    # è·³è¿‡æœ‰é—®é¢˜çš„æ–‡ä»¶
                    continue
        
        # æŒ‰æ—¶é—´å€’åºæ’åº
        backup_files.sort(key=lambda x: x['file_time'], reverse=True)
        return backup_files
    except OSError as e:
        logger.error(f"è·å–å¤‡ä»½æ–‡ä»¶åˆ—è¡¨å¤±è´¥ï¼ˆæ–‡ä»¶æ“ä½œé”™è¯¯ï¼‰: {e}", exc_info=True)
        return []
    except Exception as e:
        logger.error(f"è·å–å¤‡ä»½æ–‡ä»¶åˆ—è¡¨å¤±è´¥ï¼ˆæœªçŸ¥é”™è¯¯ï¼‰: {e}", exc_info=True)
        return []

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†ç±»"""
    
    def __init__(self):
        self.db_path = get_database_path()
        self.backup_dir = get_backup_dir()
    
    def get_conn(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        return get_conn()
    
    def init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        init_db()
    
    def insert_policy(self, level, title, pub_date, source, content, crawl_time):
        """æ’å…¥æ”¿ç­–æ•°æ®"""
        return insert_policy(level, title, pub_date, source, content, crawl_time)
    
    def search_policies(self, level=None, keywords=None, start_date=None, end_date=None):
        """æœç´¢æ”¿ç­–ï¼Œæ”¯æŒæ—¶é—´åŒºé—´"""
        return search_policies(level, keywords, start_date, end_date)
    
    def get_policy_by_id(self, policy_id):
        """æ ¹æ®IDè·å–æ”¿ç­–è¯¦æƒ…"""
        return get_policy_by_id(policy_id)
    
    def backup_database(self):
        """å¤‡ä»½æ•°æ®åº“"""
        return backup_database()
    
    def restore_database(self, backup_file):
        """ä»å¤‡ä»½æ–‡ä»¶æ¢å¤æ•°æ®åº“"""
        return restore_database(backup_file)
    
    def get_database_info(self):
        """è·å–æ•°æ®åº“ä¿¡æ¯"""
        return get_database_info()
    
    def get_backup_files(self):
        """è·å–æ‰€æœ‰å¤‡ä»½æ–‡ä»¶"""
        return get_backup_files()
    
    def cleanup_old_backups(self):
        """æ¸…ç†æ—§çš„å¤‡ä»½æ–‡ä»¶"""
        return cleanup_old_backups()
    
    def clear_database(self):
        """æ¸…ç†æ•°æ®åº“ - åˆ é™¤æ‰€æœ‰æ”¿ç­–æ•°æ®"""
        return clear_database() 